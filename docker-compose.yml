version: '3'
services:
  # Hadoop NameNode
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    hostname: hadoop-master  # 加這行，讓容器內部能用 hadoop-master 找到它
    environment:
      - CLUSTER_NAME=test
      - CORE_CONF_fs_defaultFS=hdfs://hadoop-master:9000
    ports:
      - "9870:9870"
      - "9000:9000"
    volumes:
      - ./data/raw:/data/raw
      - ./data/predict:/data/predict
    networks:
      bigdata-net:
        aliases:
          - hadoop-master  # 讓其他容器透過這個名字找到 NameNode

  # Hadoop DataNode
  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    environment:
      - CLUSTER_NAME=test
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    ports:
      - "9864:9864"  # DataNode UI
    networks:
      - bigdata-net

  # Spark Master
  spark-master:
    image: my-spark:latest
    container_name: spark-master
    hostname: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_DRIVER_BIND_ADDRESS=0.0.0.0
      - SPARK_DRIVER_HOST=spark-master  # Worker 透過這個 Hostname 回連
    ports:
      - "8080:8080"  # Spark Master UI
      - "7077:7077"  # Spark Master Communication
      - "4040-4050:4040-4050"
      - "8001:8001"
    volumes:
      - ./app:/app  # 掛載程式碼
      - ./data:/app/data/  # 掛載資料
      - ./output:/app/output
    networks:
      bigdata-net:
        ipv4_address: 172.18.0.11  # 固定 IP

  # Spark Worker 1
  spark-worker-1:
    image: bitnami/spark:3.2.4
    container_name: spark-worker-1
    user: "root"
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=8g
      - SPARK_WORKER_CORES=2
    ports:
      - "8081:8081"  # Worker 1 UI
    networks:
      - bigdata-net

  # Spark Worker 2
  spark-worker-2:
    image: bitnami/spark:3.2.4
    container_name: spark-worker-2
    user: "root"
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=4g
      - SPARK_WORKER_CORES=2
    ports:
      - "8082:8081"  # Worker 2 UI
    networks:
      - bigdata-net
  kafka:
    image: bitnami/kafka:latest
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      - KAFKA_CFG_PROCESS_ROLES=controller,broker
      - KAFKA_CFG_NODE_ID=1
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka:9093
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_LOG_DIRS=/bitnami/kafka/data
      - KAFKA_CLUSTER_ID=otfEBd2zSQKhKkRuiqtcfw  # 可選：也可省略讓它自動產生並持久化
    volumes:
      - ./kafka_data:/bitnami/kafka
    networks:
      - bigdata-net
  frontend:
    image: frontend-predict:latest
    container_name: frontend-predict
    ports:
      - "3000:3000"
    networks:
      - bigdata-net
    depends_on:
      - spark-master
volumes:
  kafka_data:
networks:
  bigdata-net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.18.0.0/16