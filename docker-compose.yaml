version: '3'
services:
  master:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: master
    hostname: hadoop-master
    environment:
      - CLUSTER_NAME=test
      - CORE_CONF_fs_defaultFS=hdfs://hadoop-master:9000
      - YARN_CONF_yarn_resourcemanager_hostname=hadoop-master
    ports:
      - "9870:9870"
      - "8088:8088"
      - "9000:9000"
    networks:
      - bigdata-net

  worker1:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: worker1
    environment:
      - CLUSTER_NAME=test
      - CORE_CONF_fs_defaultFS=hdfs://hadoop-master:9000
      - YARN_CONF_yarn_resourcemanager_hostname=hadoop-master
    ports:
      - "9864:9864"
    networks:
      - bigdata-net

  worker2:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: worker2
    environment:
      - CLUSTER_NAME=test
      - CORE_CONF_fs_defaultFS=hdfs://hadoop-master:9000
      - YARN_CONF_yarn_resourcemanager_hostname=hadoop-master
    ports:
      - "9865:9864"
    networks:
      - bigdata-net

  spark-client:
    image: bitnami/spark:3.2
    container_name: spark-client
    hostname: spark-client
    user: root
    environment:
      - HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
    volumes:
      - ./hadoop-conf:/opt/hadoop/etc/hadoop  # 修正 mount 的格式
      - ./:/app
    networks:
      - bigdata-net
    depends_on:
      - master

networks:
  bigdata-net:
    driver: bridge
