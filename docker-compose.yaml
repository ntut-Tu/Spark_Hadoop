services:
  master:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    container_name: master
    hostname: hadoop-master
    environment:
      - CLUSTER_NAME=test
      - CORE_CONF_fs_defaultFS=hdfs://hadoop-master:9000
      - YARN_CONF_yarn_resourcemanager_hostname=hadoop-master
    ports:
      - "9870:9870"  # HDFS web UI
      - "8088:8088"  # YARN ResourceManager UI
      - "9000:9000"  # HDFS NameNode RPC
    networks:
      - bigdata-net

  worker1:
    image: bde2020/hadoop-base:2.0.0-hadoop3.2.1-java8
    container_name: worker1
    hostname: worker1
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://hadoop-master:9000
      - YARN_CONF_yarn_resourcemanager_hostname=hadoop-master
      - CLUSTER_NAME=test
    command: >
      bash -c "hdfs datanode & yarn nodemanager & sleep infinity"
    ports:
      - "9864:9864"
    networks:
      - bigdata-net

  worker2:
    image: bde2020/hadoop-base:2.0.0-hadoop3.2.1-java8
    container_name: worker2
    hostname: worker2
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://hadoop-master:9000
      - YARN_CONF_yarn_resourcemanager_hostname=hadoop-master
      - CLUSTER_NAME=test
    command: > 
      bash -c "hdfs datanode & yarn nodemanager & sleep infinity"
    ports:
      - "9865:9864"
    networks:
      - bigdata-net

  spark-client:
    image: spark-client
    container_name: spark-client
    hostname: spark-client
    user: root
    environment:
      - HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
    volumes:
      - ./hadoop-conf:/opt/hadoop/etc/hadoop
      - ./:/app
    networks:
      - bigdata-net
    depends_on:
      - master

networks:
  bigdata-net:
    driver: bridge